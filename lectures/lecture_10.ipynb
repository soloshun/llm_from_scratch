{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3fd8939b",
      "metadata": {},
      "source": [
        "# **Token/Vector Embeddings**\n",
        "\n",
        "NB: lecture note found here **[ðŸ”¹ Lecture 10 Notes ðŸ”¹](lecture_10_notes.md)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d4c6a2b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5b7579",
      "metadata": {},
      "source": [
        "**how token ids are converted to vector embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b1dc1852",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids = torch.tensor([2, 3, 4, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90432e5e",
      "metadata": {},
      "source": [
        "**for simplity we use 6 words vector dimension 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "102b46d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embeddings_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ea4a0a90",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# get the weight\n",
        "print(embeddings_layer.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c6accb18",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.4015,  0.9666, -1.1481], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights = embeddings_layer.weight\n",
        "# another way to get is \n",
        "# weights_2 = embeddings_layer.state_dict()['weight']\n",
        "weights[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf546cf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# let get the te vector embedding of a particular token id\n",
        "# the idea here is the embedding layer within itself is a lookup table so looking at token ids vector embedding\n",
        "print(embeddings_layer(torch.tensor([3]))) # another way getting an embedding vector from embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2df8665",
      "metadata": {},
      "source": [
        "so essentially what is happening here is:\n",
        "![](../images/L10_vec_s8.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "16036f9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input ids: tensor([2, 3, 4, 1])\n",
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# let get the vector embedding for the input_ids we declared earlier in cell 2\n",
        "print(\"input ids:\", input_ids)\n",
        "print(embeddings_layer(input_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13d28696",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sophia-dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

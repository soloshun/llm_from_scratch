{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6371055",
   "metadata": {},
   "source": [
    "# **Implementing Self-attention with trainable weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0134835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea6072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['Your', 'journey', 'starts', 'with', 'one', 'step']\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [\n",
    "   [0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55], # step     (x^6)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7791ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38943379",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1] # A\n",
    "d_in = inputs.shape[1] # B\n",
    "d_out = 2 # C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12bf216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "# the trainable weights we're using here is 3x2. the first rows, 3 has to match the vector dimension of the input vector dimenstion. in our case 3, but the second dimension can be anything\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False) # 3x2\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb063550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.2961, 0.5166],\n",
       "        [0.2517, 0.6886],\n",
       "        [0.0740, 0.8665]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564483f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.1366, 0.1025],\n",
       "        [0.1841, 0.7264],\n",
       "        [0.3153, 0.6871]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30e178e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0756, 0.1966],\n",
       "        [0.3164, 0.4017],\n",
       "        [0.1186, 0.8274]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a75ae795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4306, 1.4551]), tensor([0.4433, 1.1419]), tensor([0.3951, 1.0037]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing for only the second in the input x_2\n",
    "query_2 = x_2 @ W_query # 1x3 @ 3x2 = 1x2\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "query_2, key_2, value_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb02a8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 2]), torch.Size([6, 2]), torch.Size([6, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing key value for all\n",
    "queries = inputs @ W_query # 6x3 @ 3x2 = 6x2\n",
    "keys = inputs @ W_key # 6x3 @ 3x2 = 6x2\n",
    "values = inputs @ W_value # 6x3 @ 3x2 = 6x2\n",
    "\n",
    "queries.shape, keys.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7094a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8524)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the attention score for w22\n",
    "key_2 = keys[1]\n",
    "attn_score_22 = query_2.dot(key_2) \n",
    "attn_score_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b13ce2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T # 1X2 @ 2X6\n",
    "attn_scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd586fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
       "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
       "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
       "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
       "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
       "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = queries @ keys.T # 6x2 @ 2x6 -> omega\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c78b307",
   "metadata": {},
   "source": [
    "we compute the attention weight by scaling the attention scores and using the softmax function. we scale the attention scores by dividing them with the square root of the embedding dimention of the key matrixs\n",
    "\n",
    "**note that taking the sqaure root is mathematically the same as exponentiating by 0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bef3058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820]), 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = keys.shape[-1] # dimension of keys matrix\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "attn_weights_2, d_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef0bfd",
   "metadata": {},
   "source": [
    "## **WHY DIVIDE BY SQRT (DIMENSION)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130b414",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Reason 1: For stability in learning\n",
    "\n",
    "The softmax function is sensitive to the magnitudes of its inputs. When the inputs are large, the differences between the exponential values of each input become much more pronounced. This causes the softmax output to become \"peaky,\" where the highest value receives almost all the probability mass, and the rest receive very little.\n",
    "\n",
    "In attention mechanisms, particularly in transformers, if the dot products between query and key vectors become too large (like multiplying by 8 in this example), the attention scores can become very large. This results in a very sharp softmax distribution, making the model overly confident in one particular \"key.\" Such sharp distributions can make learning unstable,\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2dda49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax without scaling: tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
      "Softmax after scaling (tensor * 8): tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
     ]
    }
   ],
   "source": [
    "# define the tensor\n",
    "tensor  = torch.tensor([0.1, -0.2,0.3,-0.2,0.5])\n",
    "\n",
    "# apply softmax without scaling\n",
    "softmax_result = torch.softmax(tensor, dim=-1)\n",
    "print(f\"Softmax without scaling: {softmax_result}\")\n",
    "\n",
    "# multiply the tensor by 8 and then apply softmax\n",
    "scaled_tensor = tensor * 8\n",
    "softmax_scaled_result = torch.softmax(scaled_tensor, dim=-1)\n",
    "print(f\"Softmax after scaling (tensor * 8): {softmax_scaled_result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffbd780",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Reason 2: To make the variance of the dot product stable\n",
    "\n",
    "The dot product of  Q and K increases the variance because multiplying two random numbers increases the variance.\n",
    "\n",
    "The increase in variance grows with the dimension. \n",
    "\n",
    "Dividing by sqrt (dimension) keeps the variance close to 1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e88f0554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance before scaling (dim=5): 4.692901219967951\n",
      "Variance after scaling (dim=5): 0.9385802439935901\n",
      "Variance before scaling (dim=100): 98.83632170475772\n",
      "Variance after scaling (dim=100): 0.9883632170475772\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to compute variance before and after scaling\n",
    "def compute_variance(dim, num_trials=1000):\n",
    "    dot_products = []\n",
    "    scaled_dot_products = []\n",
    "\n",
    "    # Generate multiple random vectors and compute dot products\n",
    "    for _ in range(num_trials):\n",
    "        q = np.random.randn(dim)\n",
    "        k = np.random.randn(dim)\n",
    "        \n",
    "        # Compute dot product\n",
    "        dot_product = np.dot(q, k)\n",
    "        dot_products.append(dot_product)\n",
    "        \n",
    "        # Scale the dot product by sqrt(dim)\n",
    "        scaled_dot_product = dot_product / np.sqrt(dim)\n",
    "        scaled_dot_products.append(scaled_dot_product)\n",
    "    \n",
    "    # Calculate variance of the dot products\n",
    "    variance_before_scaling = np.var(dot_products)\n",
    "    variance_after_scaling = np.var(scaled_dot_products)\n",
    "\n",
    "    return variance_before_scaling, variance_after_scaling\n",
    "\n",
    "# For dimension 5\n",
    "variance_before_5, variance_after_5 = compute_variance(5)\n",
    "print(f\"Variance before scaling (dim=5): {variance_before_5}\")\n",
    "print(f\"Variance after scaling (dim=5): {variance_after_5}\")\n",
    "\n",
    "# For dimension 20\n",
    "variance_before_100, variance_after_100 = compute_variance(100)\n",
    "print(f\"Variance before scaling (dim=100): {variance_before_100}\")\n",
    "print(f\"Variance after scaling (dim=100): {variance_after_100}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3623f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3061, 0.8210])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "context_vec_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af69bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        # S = QKᵀ/√dₖ \n",
    "        attn_scores = queries @ keys.T \n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97b6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2996, 0.8053],\n",
       "        [0.3061, 0.8210],\n",
       "        [0.3058, 0.8203],\n",
       "        [0.2948, 0.7939],\n",
       "        [0.2927, 0.7891],\n",
       "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in=d_in, d_out=d_out)\n",
    "sa_v1.forward(inputs) # or sa_v1(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75d9d5",
   "metadata": {},
   "source": [
    "### Why use `nn.Linear` instead of `nn.Parameter` in self-attention?\n",
    "\n",
    "- **`nn.Parameter`**: Just a tensor marked as learnable.  \n",
    "  - Gives full manual control (init, bias, forward math).  \n",
    "  - But you must code all matrix multiplications yourself.  \n",
    "\n",
    "- **`nn.Linear`**: A higher-level layer.  \n",
    "  - Wraps weights (`nn.Parameter`) + optional bias.  \n",
    "  - Provides the forward pass `x @ W^T + b` automatically.  \n",
    "  - Handles parameter initialization and shape checks.  \n",
    "  - Uses optimized backend kernels for speed.  \n",
    "\n",
    "✅ In practice (e.g., Transformers/LLMs), we prefer `nn.Linear` for query/key/value projections because it is cleaner, less error-prone, and leverages PyTorch’s optimizations.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f4e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        # S = QKᵀ/√dₖ \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "375aa8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0739,  0.0713],\n",
       "        [-0.0748,  0.0703],\n",
       "        [-0.0749,  0.0702],\n",
       "        [-0.0760,  0.0685],\n",
       "        [-0.0763,  0.0679],\n",
       "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "sa_v2(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sophia-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

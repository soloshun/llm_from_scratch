{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa7e03f",
   "metadata": {},
   "source": [
    "# **POSITIONAL EMBEDDINGS (ENCODING WORD POSITIONS)**\n",
    "\n",
    "NB: lecture note found here **[ðŸ”¹ Lecture 11 Notes ðŸ”¹](lecture_11_notes.md)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df607378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from custom_dataloader import create_dataloader_v1, GPTDatasetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed7c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/the-verdict.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "828fd0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6650, -0.3960, -1.6920,  ...,  0.6323, -0.3739, -1.9089],\n",
       "        [-0.6729, -1.0566, -0.1262,  ...,  0.9918, -1.6732,  0.6297],\n",
       "        [ 1.1916,  0.3991,  0.7348,  ..., -1.2732,  1.2927, -0.3377],\n",
       "        ...,\n",
       "        [-0.8206,  0.0044, -0.8874,  ...,  1.2985,  0.3450,  1.5208],\n",
       "        [ 1.9297, -0.3648,  0.3911,  ..., -0.0544,  0.3523, -1.1824],\n",
       "        [-1.0308,  0.4683, -1.8401,  ...,  1.6654, -1.3470,  0.2870]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "token_embedding_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbe4ef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-6.6501e-01, -3.9598e-01, -1.6920e+00,  4.3930e-01, -3.3955e-01,\n",
       "         -5.5913e-01,  5.9424e-01,  1.0151e-01,  1.5785e-01,  6.6164e-01,\n",
       "          4.1983e-01, -8.1297e-01,  1.7353e+00,  5.1869e-01,  1.2715e+00,\n",
       "          1.0389e+00, -1.1038e+00,  6.5114e-01, -1.1008e+00, -4.0501e-01,\n",
       "         -6.9144e-02, -8.8717e-01,  1.2001e+00, -2.7480e-01, -4.0364e-01,\n",
       "          4.1064e-01,  2.1192e+00,  2.2398e-01, -8.2687e-01,  5.6745e-01,\n",
       "          9.2227e-02,  1.6636e+00,  9.5709e-01,  4.9087e-01, -2.2391e-01,\n",
       "          3.9019e-01, -7.3762e-01,  3.8206e-01,  9.0920e-01, -1.5982e+00,\n",
       "          1.1482e-01,  1.7040e+00, -1.5467e+00,  1.3963e-01,  6.0206e-01,\n",
       "          5.2654e-01, -1.0954e+00, -3.2106e-01, -1.5207e+00, -1.1420e+00,\n",
       "         -1.7619e+00,  6.5756e-04, -1.7530e+00,  7.3386e-01, -1.5916e+00,\n",
       "          2.2092e+00,  1.5543e-01,  8.9082e-01,  8.9937e-01, -5.5425e-01,\n",
       "          7.5784e-01, -2.1007e+00, -2.4645e+00,  1.0643e+00, -9.0369e-01,\n",
       "          1.5556e+00, -1.1885e+00, -1.2958e+00, -4.7220e-01,  1.0260e+00,\n",
       "         -9.5041e-01, -3.3155e-02, -8.9497e-01, -8.0831e-02,  1.4432e+00,\n",
       "         -2.4299e+00,  5.2950e-02,  6.1177e-01, -1.2659e+00,  4.5382e-02,\n",
       "          1.1815e+00, -1.1575e+00,  4.1854e-01,  4.8376e-01, -8.2853e-01,\n",
       "          1.6262e-01,  1.4278e+00, -2.0985e-01, -4.6216e-01, -8.2207e-01,\n",
       "         -5.1364e-02,  5.5474e-01, -2.1440e-04, -1.4600e+00,  7.0780e-01,\n",
       "          1.4608e+00,  5.2355e-01,  2.9745e-01,  5.2708e-01, -2.2726e-01,\n",
       "          5.4897e-02,  6.7076e-01,  7.2543e-01, -5.6774e-01, -3.5370e-01,\n",
       "          4.9201e-01, -1.4891e-01,  8.0572e-01, -3.8641e-01, -9.3408e-01,\n",
       "         -4.8869e-01, -1.5568e+00, -1.5160e-01, -1.0809e+00, -2.2886e+00,\n",
       "         -1.8273e-01,  7.0935e-02,  1.2020e+00, -9.6624e-01, -6.3636e-01,\n",
       "          1.0727e-01, -6.0334e-01, -1.6269e+00,  6.8040e-02, -1.8495e+00,\n",
       "          8.0767e-01,  4.7976e-01,  2.5500e-01,  2.1331e-01, -1.1289e+00,\n",
       "          4.3675e-01, -1.0791e+00,  4.7239e-01, -2.2144e-01, -1.0777e+00,\n",
       "          6.3625e-01,  7.2014e-02,  1.7292e-03, -4.8100e-01,  2.1030e-01,\n",
       "         -1.2128e+00,  1.1279e+00, -8.9887e-01, -1.2603e-01, -2.4665e+00,\n",
       "         -3.5112e-01,  9.5192e-01, -1.1556e+00,  7.6639e-01,  2.1487e-01,\n",
       "         -5.2062e-01, -7.1030e-01,  1.2231e-01,  7.2362e-01,  5.6230e-01,\n",
       "         -8.2452e-01,  2.1643e+00, -1.5696e+00,  5.6189e-01,  1.0903e-01,\n",
       "          4.6120e-01, -4.2920e-01,  7.9993e-01,  1.0732e+00,  1.0617e+00,\n",
       "          7.8716e-01, -4.0909e-01,  1.1656e+00, -5.4712e-01, -1.5827e-01,\n",
       "         -1.2636e+00,  1.2058e-01,  1.4367e+00, -1.7946e+00, -6.3490e-01,\n",
       "         -6.4883e-01,  2.4363e-01, -1.5498e-01,  1.9769e+00, -5.7328e-01,\n",
       "          1.2874e+00, -1.2112e+00,  5.0971e-01, -8.0384e-01,  1.4610e-02,\n",
       "         -7.5651e-01,  1.4784e+00,  3.9846e-01,  9.1110e-01, -2.6654e-01,\n",
       "         -8.8905e-01, -2.0362e-01,  5.0997e-01, -7.2502e-01, -4.6843e-01,\n",
       "          1.8342e+00,  1.3614e+00,  2.6985e+00,  8.9121e-01,  7.2635e-01,\n",
       "          8.5587e-01,  3.5205e-01, -1.3349e+00,  7.1669e-01,  8.3914e-01,\n",
       "          8.3248e-01,  7.3625e-01, -9.8392e-02,  9.6052e-01, -1.3656e-01,\n",
       "         -6.0784e-01,  1.1310e-01, -1.3405e+00, -5.5323e-02, -1.3854e+00,\n",
       "          2.0419e+00,  3.2359e-01, -1.0444e+00,  2.2539e-01,  1.0075e+00,\n",
       "          8.8319e-01,  2.2514e-01,  2.2536e-01, -2.7418e-01,  1.6322e+00,\n",
       "          4.5340e-01,  1.9413e+00, -6.0554e-01,  2.6787e+00, -8.9121e-01,\n",
       "         -2.2007e+00,  1.4920e+00,  2.3588e+00, -7.5071e-01, -3.6145e-01,\n",
       "          8.3576e-01, -9.0125e-01, -1.2881e+00, -2.4608e-01, -1.6200e-01,\n",
       "          1.5239e+00,  6.7268e-01,  4.7151e-01, -9.5596e-01,  1.9497e+00,\n",
       "         -2.3120e-01, -4.3756e-01, -7.5213e-01, -2.3831e-01,  1.0002e+00,\n",
       "         -4.5034e-02,  9.7648e-01, -7.7243e-01,  6.3235e-01, -3.7387e-01,\n",
       "         -1.9089e+00], grad_fn=<SelectBackward0>),\n",
       " torch.Size([256]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding_layer.weight[0], token_embedding_layer.weight[0].shape # this is one vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c74630bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the data loader\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, \n",
    "    batch_size=8, \n",
    "    max_length=max_length,\n",
    "    stride=max_length,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8ea29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Input shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token IDs:\\n {inputs}\")\n",
    "print(f\"\\nInput shape:\\n {inputs.shape}\")\n",
    "# print(f\"\\Target:\\n {targets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a8dc86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n",
      "tensor([[[-0.2046, -1.8466, -0.6487,  ..., -0.2582,  0.1805, -0.3588],\n",
      "         [ 2.0577,  0.4270,  0.8602,  ..., -2.3949,  1.9270, -0.3367],\n",
      "         [ 0.3987,  0.3101, -0.4292,  ..., -0.2538, -0.3918,  0.1003],\n",
      "         [-0.2639,  1.0121,  2.9990,  ..., -0.8792, -0.3242, -2.2238]],\n",
      "\n",
      "        [[-0.2239,  0.0800,  0.3958,  ...,  1.3972, -0.5631,  2.5883],\n",
      "         [ 0.2781, -0.5884,  0.2849,  ...,  0.0181,  0.9689,  1.3072],\n",
      "         [ 0.8199, -0.7313,  0.4791,  ..., -0.5266, -0.6722, -0.3094],\n",
      "         [ 1.6827, -0.9518,  1.0688,  ..., -1.0927,  0.5437, -0.6888]],\n",
      "\n",
      "        [[ 0.4752, -0.6191, -1.0162,  ...,  0.9022,  1.2743, -0.5299],\n",
      "         [ 0.1380, -0.1904,  0.1648,  ..., -1.0455,  0.9159, -0.4218],\n",
      "         [ 1.3723,  0.2261, -0.4622,  ...,  1.9858, -0.1862,  0.3600],\n",
      "         [ 1.4143, -1.5072, -0.3089,  ..., -1.1498,  0.7676,  1.2589]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9453,  0.8578,  0.8378,  ..., -0.2496,  0.0051, -0.4226],\n",
      "         [ 0.4659,  0.0655, -0.1561,  ..., -1.2765, -2.3105, -0.5968],\n",
      "         [ 1.0430, -0.4642,  1.6193,  ..., -0.4981, -0.5306,  1.8482],\n",
      "         [ 1.0820, -1.4108, -2.0007,  ..., -0.8746,  1.8595, -0.2062]],\n",
      "\n",
      "        [[ 0.5931, -0.6267, -2.1910,  ...,  0.6377, -1.9404, -0.6749],\n",
      "         [ 0.4979,  0.3229,  0.3765,  ...,  0.2854,  0.1748,  1.4893],\n",
      "         [ 0.2466, -0.5134,  1.3042,  ..., -0.4123, -1.5892,  0.1228],\n",
      "         [-1.2840,  0.5848,  1.9598,  ...,  1.9492, -0.0899, -0.0915]],\n",
      "\n",
      "        [[ 0.2466, -0.5134,  1.3042,  ..., -0.4123, -1.5892,  0.1228],\n",
      "         [ 0.5247, -0.4351,  1.1785,  ..., -1.5910,  1.2749, -0.6137],\n",
      "         [-0.5825,  0.2985, -1.0600,  ...,  1.0670,  0.3591, -1.1114],\n",
      "         [-0.3433,  2.0206, -0.9459,  ...,  1.5153,  0.9203,  0.2821]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# for each in a batch, one embedding vector of `256` length is generated for each token in input\n",
    "token_embedding = token_embedding_layer(inputs)\n",
    "print(token_embedding.shape)\n",
    "print(token_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a77ea24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2046, -1.8466, -0.6487,  ..., -0.2582,  0.1805, -0.3588],\n",
       "        [ 2.0577,  0.4270,  0.8602,  ..., -2.3949,  1.9270, -0.3367],\n",
       "        [ 0.3987,  0.3101, -0.4292,  ..., -0.2538, -0.3918,  0.1003],\n",
       "        [-0.2639,  1.0121,  2.9990,  ..., -0.8792, -0.3242, -2.2238]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "909cc0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2046, -1.8466, -0.6487,  1.7777,  0.3168,  1.3174,  0.6371,  0.1363,\n",
       "         0.4252,  1.1606, -1.1153, -1.1815, -1.8826,  0.2098, -0.7317,  1.7523,\n",
       "        -0.5189, -1.3398,  0.3115, -0.2412,  1.5987, -1.4546, -0.5183, -0.0564,\n",
       "        -0.0848, -0.8238,  1.7346, -0.8185, -0.6581,  0.5450, -0.5677, -0.4923,\n",
       "         0.5269,  0.4290,  1.5571,  0.0674, -1.5752, -1.1630, -2.0091,  0.1694,\n",
       "         0.1650,  1.8256,  0.2122, -0.0271,  1.1922, -0.4513,  1.5860, -2.2039,\n",
       "         0.2653,  1.0871, -0.8103, -0.1782, -0.1119,  0.1606, -0.4982, -1.6447,\n",
       "        -0.0306,  0.8655, -0.6684,  0.1114,  0.6961, -0.3315,  1.1788, -1.6366,\n",
       "        -0.4531,  1.6445, -0.0268, -0.0833, -0.1129, -0.3096, -0.3807, -0.4678,\n",
       "         1.3557,  1.0988,  0.7483,  0.1273, -0.3438, -1.9202,  0.0170,  1.5317,\n",
       "        -0.1547,  0.4188,  0.6444, -0.6848,  2.6404,  0.4245,  0.6672, -0.7766,\n",
       "         0.2676, -1.4277, -1.0998,  2.3620, -0.2716, -0.0071,  0.6622, -1.3912,\n",
       "         0.7988, -0.1226,  0.1014, -0.6018,  0.6969,  0.2354,  0.2742,  0.8385,\n",
       "         0.2536,  0.4602, -0.3506, -0.3721, -0.9197, -0.2104,  0.6824,  0.6837,\n",
       "         0.1826, -0.2827,  0.1075, -0.3161, -0.7288, -0.4866,  1.7757, -0.2687,\n",
       "        -1.2265, -0.2722,  0.0409, -0.2193,  0.1031, -1.8512,  0.4099, -0.3200,\n",
       "         0.1582, -0.1229,  0.0121, -0.1238, -0.4331,  0.6782,  1.8093, -0.2032,\n",
       "        -0.3441,  2.3121,  1.0412, -1.7082, -2.9360,  0.7801, -1.5958,  0.1252,\n",
       "        -0.3333,  1.1715, -0.0336, -0.6851, -0.3846,  0.4773, -0.5196,  0.4255,\n",
       "         0.4812, -0.5010, -0.7223,  0.9179,  1.0208, -0.3793,  1.1638,  0.6765,\n",
       "         0.3356,  0.9161,  0.0516,  0.9108, -0.4421,  0.4312, -2.2774, -0.8561,\n",
       "         0.3827,  0.2265,  0.5509, -0.1659,  1.3588,  1.3194, -0.1664,  1.8375,\n",
       "        -0.7659, -2.1313, -0.4496, -1.0578, -0.5745, -0.7441, -2.9598,  0.6721,\n",
       "         0.7372, -0.1118,  0.2410,  0.5798, -1.6192,  1.4207, -0.7981, -0.0831,\n",
       "        -0.4558,  0.5341,  0.0304, -0.4988, -1.6760,  1.4698,  0.2075,  0.4418,\n",
       "        -0.6691, -0.0386, -0.5021,  0.1836,  1.1587, -1.8497,  1.9431,  1.2015,\n",
       "         0.3616,  2.4039,  0.5625, -0.2015,  1.4366,  0.8147, -0.5616,  0.3729,\n",
       "        -0.7689, -0.2331, -0.6683,  0.2630, -0.8045,  0.1776,  0.6873,  0.4524,\n",
       "        -0.4614,  0.1389,  2.7221, -0.7176,  0.7182, -0.5713,  0.8705,  1.0645,\n",
       "         1.1635, -0.3698,  0.2527, -0.9996,  0.7376, -0.8870, -1.1150, -0.5857,\n",
       "         0.1114,  1.2609,  0.8525, -0.3650, -0.0236,  0.3642, -0.0674,  2.2066,\n",
       "        -1.0521,  0.0091,  0.5106,  0.4384,  0.7733, -0.2582,  0.1805, -0.3588],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding[0][0] # token embedding for token id 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "608da9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.3488,  1.0694,  1.2844,  ...,  0.8013,  0.4989,  0.0151],\n",
       "         [-1.3783, -0.5850,  0.3231,  ..., -0.6046, -0.1767,  0.2799],\n",
       "         [ 0.2607,  0.0254,  0.5547,  ..., -0.3113, -0.8192, -1.2281],\n",
       "         [-1.5563,  2.0962,  0.2940,  ..., -1.0076,  0.4094,  0.9149]],\n",
       "        requires_grad=True),\n",
       " torch.Size([4, 256]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = max_length\n",
    "# in position encoding, the number of rows should always be the same as the context length and also the columns should also match vector dimension\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embedding_layer.weight, pos_embedding_layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df48401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n",
      "tensor([[-0.3488,  1.0694,  1.2844,  ...,  0.8013,  0.4989,  0.0151],\n",
      "        [-1.3783, -0.5850,  0.3231,  ..., -0.6046, -0.1767,  0.2799],\n",
      "        [ 0.2607,  0.0254,  0.5547,  ..., -0.3113, -0.8192, -1.2281],\n",
      "        [-1.5563,  2.0962,  0.2940,  ..., -1.0076,  0.4094,  0.9149]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)\n",
    "print(pos_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295007d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sophia-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
